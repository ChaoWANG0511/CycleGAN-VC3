# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gxE2D9gCo-5o6xnkSrMEjdjuSCDe8gSu
"""

#! pip install mcd

#! pip install pysptk
#! pip install fastdtw

#! pip install pyworld
#! pip install soundfile

import numpy as np
import os
import argparse
import time
import librosa
import pickle
from tqdm import tqdm
import torch
import re
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.utils.spectral_norm as spectral_norm
import IPython.display as display
import gc
from torch.utils.data.dataset import Dataset
import math

from scipy.io import wavfile
#import pyworld as pw
import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
import librosa.display
import IPython.display as ipd
from os import walk
import IPython.display as display
import torch
from scipy.signal import get_window
import librosa.util as librosa_util
import torch.nn.functional as F
from torch.autograd import Variable
from scipy.signal import get_window
from librosa.util import pad_center, tiny
from librosa.filters import mel as librosa_mel_fn # Create a Filterbank matrix to combine FFT bins into Mel-frequency bins
import glob
import tqdm
import random
import subprocess
from scipy.io.wavfile import read
import yaml
from torch.utils.data.dataset import Dataset
import pickle

import argparse

from tqdm import tqdm
from os.path import exists, dirname, basename, join
from scipy.fftpack import fft

import statistics
import numpy as np
import librosa
from scipy.io import wavfile
import pysptk
from scipy.spatial.distance import euclidean
import os
from fastdtw import fastdtw

import soundfile as sf
import pyworld as pw
from shutil import rmtree

from matplotlib.pyplot import savefig

def MCDList(natural_folder, synth_folder, score = 'mcd'):
  # you need to make sure all waveform files in these above folders have the same file name !

  MCD_value = []
  _logdb_const = 10.0 / np.log(10.0) * np.sqrt(2.0)
  s = 0.0
  
  framesTot = 0

  files = os.listdir(natural_folder)
  nb = len(os.listdir(synth_folder))
  l_true_path = os.listdir(natural_folder)
  j = 0
  for i, file in enumerate(os.listdir(synth_folder)):
    AoutBPath = os.path.join(synth_folder, file) 
    if os.path.exists(os.path.join(natural_folder, file)):
      BtarPath = os.path.join(natural_folder, file)
      j += 1
    else:
      continue

    AoutB, f0_ho, ap_ho, xo = wav2coded_sp(AoutBPath)
    Btar, f0_ht, ap_ht, xt = wav2coded_sp(BtarPath)
      
    print("Processing -----------{}".format(file))
    x = AoutB
    y = Btar
    #print(x.shape, y.shape)

    minT = min(x.shape[1], y.shape[1])
    x = x[:, :minT]
    y = y[:, :minT]
    
    distance, path = fastdtw(x, y, dist=euclidean)

    distance/= (len(x) + len(y))
    pathx = list(map(lambda l: l[0], path))
    pathy = list(map(lambda l: l[1], path))
    x, y = x[pathx], y[pathy]
    if score == 'mcd':
      score = mcd(x, y)
    else:
      score = msd(x, y)
    print(score)

    MCD_value.append(np.min(score)) # mcd

  #print("MCD = : {:f}+-{:f}".format(sum(MCD_value)/j, statistics.stdev(MCD_value)))

  return MCD_value

#35-dimensional mel-cepstrum parameters were extracted from the target or converted waveform using WORLD
n_mel_channels= 80
segment_length= 16000
pad_short= 2000
filter_length= 1024
hop_length= 256 # WARNING: this can't be changed.
win_length= 1024
sampling_rate= 22050
mel_fmin= 0.0
mel_fmax= 8000.0
n_mfcc = 35

path="/content/drive/MyDrive/My_CycleGAN"
os.chdir(path)

def wav2coded_sp(wav_file):
    # load wav
    x, fs = sf.read(wav_file)

    # 2-3 Harvest with F0 refinement (using Stonemask)
    _f0_h, t_h = pw.harvest(x, fs)
    f0_h = pw.stonemask(x, _f0_h, t_h, fs)
    sp_h = pw.cheaptrick(x, f0_h, t_h, fs) # Harmonic spectral envelope
    ap_h = pw.d4c(x, f0_h, t_h, fs)

    # Get Mel-cepstral coefficients (MCEPs)
    coded_sp = pw.code_spectral_envelope(sp_h, fs, 35)

    return coded_sp, f0_h, ap_h, x


# Mel-cepstral distortion (MCD) = distance between the target and converted MCEP sequences
def mcd(cvt, trg):
    #print('D=35', cvt.shape[1])
    minT = min(cvt.shape[0], trg.shape[0])
    alpha = (10 * np.sqrt(2)) / np.log(10) 
    return alpha * np.mean(np.sqrt(np.sum((trg[:minT, 1:] - cvt[:minT, 1:]) ** 2, axis=1))) # 先D，后T


# modulation spectra distance (MSD) = root mean square error between the target and converted logarithmic modulation 
# spectra of MCEPs 
# averaged over all MCEP dimensions and modulation frequencies
def msd(cvt, trg):
    #print(fft(cvt.T).max(), fft(cvt).T.max()) # (1916.5970984190676-0j) (-1.6122297271751669+0.515492935126461j)
    
    cvt_ms = np.log(np.abs(fft(cvt.T, n = 80)))  #fft(cvt.T, n = 64)
    trg_ms = np.log(np.abs(fft(trg.T, n = 80)))  # (35,583) (35,476) 

    minT = min(cvt.shape[1], trg.shape[1])
    msd = np.sqrt(np.mean((cvt_ms[:, :minT] - trg_ms[:, :minT])**2))
    #msd = np.ma.sqrt(np.ma.mean((cvt- trg)**2))
    return msd

def savefigs(filename, figlist, log=True):
    #h = 10
    EPSILON = 1e-8
    n = len(figlist)
    # peek into instances
    f = figlist[0]
    if len(f.shape) == 1:
        plt.figure()
        for i, f in enumerate(figlist):
            plt.subplot(n, 1, i+1)
            if len(f.shape) == 1:
                plt.plot(f)
                plt.xlim([0, len(f)])
    elif len(f.shape) == 2:
        Nsmp, dim = figlist[0].shape
        #figsize=(h * float(Nsmp) / dim, len(figlist) * h)
        #plt.figure(figsize=figsize)
        plt.figure()
        for i, f in enumerate(figlist):
            plt.subplot(n, 1, i+1)
            if log:
                x = np.log(f + EPSILON)
            else:
                x = f + EPSILON
            plt.imshow(x.T, origin='lower', interpolation='none', aspect='auto', extent=(0, x.shape[0], 0, x.shape[1]))
    else:
        raise ValueError('Input dimension must < 3.')
    plt.savefig(filename)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="generate training dataset and stats")

    source_path = './vcc2020_database_training_source/source/SEM1/'
    target_path = './vcc2020_database_training_target_task1/target_task1/TEM2/'

    true_A_dir = source_path
    output_B_dir = './vcc2020_database_evaluation/vcc2020_database_evaluation/B2A_M2toM1'

    true_B_dir = target_path
    output_A_dir = './vcc2020_database_evaluation/vcc2020_database_evaluation/A2B_M1toM2'

    parser.add_argument('--true_A_dir', type=str,
                        help="real A", default=true_A_dir)
    parser.add_argument('--output_B_dir', type=str,
                        help="converted A from B", default=output_B_dir)
    parser.add_argument('--true_B_dir', type=str,
                        help="real B", default=true_B_dir)
    parser.add_argument('--output_A_dir', type=str,
                        help="converted B from A", default=output_A_dir)
    
        
    argv, unknown = parser.parse_known_args()

    true_A_dir = argv.true_A_dir
    output_B_dir = argv.output_B_dir
    true_B_dir = argv.true_B_dir
    output_A_dir = argv.output_A_dir


    # Comparison
    if os.path.isdir('./test'):
      rmtree('./test')
    os.mkdir('./test')


    nb = len(os.listdir(output_A_dir))
    l_true_path = os.listdir(true_B_dir)
    for i, file in enumerate(os.listdir(output_A_dir)):
      AoutBPath = os.path.join(output_A_dir, file) 
      if os.path.exists(os.path.join(true_B_dir, file)):
        BtarPath = os.path.join(true_B_dir, file)
      else:
        BtarPath = os.path.join(true_B_dir, l_true_path[i])  
      
      AoutB, f0_ho, ap_ho, xo = wav2coded_sp(AoutBPath)
      Btar, f0_ht, ap_ht, xt = wav2coded_sp(BtarPath)

      Asoui, f0_hi, ap_hi, xi = wav2coded_sp(os.path.join(true_A_dir, file)) 

      # Comparison

      print(file[:-4])
      savefigs('./test/A2Bwavform'+file[:-4]+'.png', [xi, xo, xt])
      savefigs('./test/A2Bsp'+file[:-4]+'.png', [Asoui, AoutB, Btar])
      savefigs('./test/A2Bap'+file[:-4]+'.png', [ap_hi, ap_ho, ap_ht], log=False)
      savefigs('./test/A2Bf0'+file[:-4]+'.png', [f0_hi, f0_ho, f0_ht])

    ##################################################################################

    nb = len(os.listdir(output_B_dir))
    l_true_path = os.listdir(true_A_dir)

    for i, file in enumerate(os.listdir(output_B_dir)):
      BoutAPath = os.path.join(output_B_dir, file) 

      if os.path.exists(os.path.join(true_A_dir, file)):
        AtarPath = os.path.join(true_A_dir, file)
      else:
        AtarPath = os.path.join(true_A_dir, l_true_path[i])  
      
      BoutA, f0_ho, ap_ho, xo = wav2coded_sp(BoutAPath)
      Atar, f0_ht, ap_ht, xt = wav2coded_sp(AtarPath)

      Bsoui, f0_hi, ap_hi, xi = wav2coded_sp(os.path.join(true_B_dir, file)) 

      print(file[:-4])
      savefigs('./test/B2Awavform_'+file[:-4]+'.png', [xi, xo, xt])
      savefigs('./test/B2Asp_'+file[:-4]+'.png', [Bsoui, BoutA, Atar])
      savefigs('./test/B2Aap_'+file[:-4]+'.png', [ap_hi, ap_ho, ap_ht], log=False)
      savefigs('./test/B2Af0_'+file[:-4]+'.png', [f0_hi, f0_ho, f0_ht])

    ##################################################################################
      
    natural_folders = [true_A_dir,true_B_dir]
    synth_folders = [output_B_dir,output_A_dir]
    task = ['B to A', 'A to B']
    for score in ('mcd', 'msd'):
      for i in range(2):
        natural_folder = natural_folders[i]
        synth_folder = synth_folders[i]
        MCD_valueB2A = MCDList(natural_folder,synth_folder,score = score)

        natural_folder = true_B_dir
        synth_folder = output_A_dir
        MCD_valueA2B = MCDList(natural_folder,synth_folder,score = score)

        print(score, ' B2A : %f ± %f'%(float(sum(MCD_valueB2A)/len(MCD_valueB2A)), float(statistics.stdev(MCD_valueB2A))))
        print(score, ' A2B : %f ± %f'%(sum(MCD_valueA2B)/len(MCD_valueA2B), statistics.stdev(MCD_valueA2B)))

        fig, axs = plt.subplots(1,2, sharey=True, tight_layout=True)

        bins2 = np.linspace(min(MCD_valueB2A)-0.1, 
                        max(MCD_valueB2A)+0.1,
                        20) # fixed number of bins

        axs[0].set_xlim([min(MCD_valueB2A)-0.01, max(MCD_valueB2A)+0.01])

        axs[0].hist(MCD_valueB2A, bins=bins2, alpha=0.5)
        axs[0].set_title('msd distribution B2A')
        axs[0].set_xlabel('msd')
        axs[0].set_ylabel('count')

        bins = np.linspace(min(MCD_valueA2B)-0.1, 
                        max(MCD_valueA2B)+0.1,
                        20) # fixed number of bins

        axs[1].set_xlim([min(MCD_valueA2B)-0.2, max(MCD_valueA2B)+0.2])

        axs[1].hist(MCD_valueA2B, bins=bins, alpha=0.5)
        axs[1].set_title(score+ ' ' + task +' distribution')
        axs[1].set_xlabel(score)
        axs[1].set_ylabel('count')

        savefig('./test/'+score+task+'.png', log=False)
        fig.show()

"""$$
\operatorname{RMSD}(\hat{\theta})=\sqrt{\operatorname{MSE}(\hat{\theta})}=\sqrt{\mathrm{E}\left((\hat{\theta}-\theta)^{2}\right)}
$$

确定这个频谱包络的算法有很多，例如常见的是倒谱法（Cepstrum，有趣的是，cepstrum与spectrum两个单词只是开头四个字母翻转了位置而已，这其实也暗示了它们的物理含义有某种巧合的关联...），在WORLD中，使用的是CheapTrick算法来估计频谱包络，该算法工作流程如下：

首先，对信号添加Hanning window，然后对windowed之后的信号计算其功率，公式如下(1)所示；

其次，使用矩形窗函数对功率谱进行平滑化，公式如下(2)所示；

最后，计算功率谱的倒谱，并做倒谱提升，公式如下(3)(4)(5)(6)所示；

$$
\begin{array}{l}
\int_{0}^{3 T_{0}}(y(t) w(t))^{2} d t=1.125 \int_{0}^{T_{0}} y^{2}(t) d t \\
P_{s}(\omega)=\frac{3}{2 \omega_{0}} \int_{-\frac{\omega_{0}}{3}}^{\frac{\omega_{0}}{3}} P(\omega+\lambda) d \lambda \\
P_{l}(\omega)=\exp \left(\mathcal{F}\left[l_{s}(\tau) l_{q}(\tau) p_{s}(\tau)\right]\right)

l_{s}(\tau)=\frac{\sin \left(\pi f_{0} \tau\right)}{\pi f_{0} \tau} \\
l_{q}(\tau)=\tilde{q}_{0}+2 \tilde{q}_{1} \cos \left(\frac{2 \pi \tau}{T_{0}}\right) \\
p_{s}(\tau)=\mathcal{F}^{-1}\left[\log \left(P_{s}(\omega)\right)\right]
\end{array}
$$

where, $l_{s}(\tau)$ represents the liftering function for smoothing and $l_{q}(\tau)$ represents the liftering function for spectral recovery derived from Eq. $(5) . \tilde{q}_{0}$ and $\tilde{q}_{1}$ are the parameters for spectral recovery. Symbol $\mathscr{F}[]$ and $\mathscr{F}^{-1}[]$ represent Fourier transform and its inverse transform.

Efficient implementation of a deep learning algorithm and experimental evaluation.
"""