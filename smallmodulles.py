# -*- coding: utf-8 -*-
"""smallmodulles.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IFWTHO-Kf1HCmNOHUndL8sOH4Zn6NPfS
"""

import numpy as np
import os
import argparse
import time
import librosa
import pickle
from tqdm import tqdm
import torch
import re
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.utils.spectral_norm as spectral_norm
import IPython.display as display
import gc
from torch.utils.data.dataset import Dataset

class downSample_Generator(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(downSample_Generator, self).__init__()

        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,
                              out_channels=out_channels,
                              kernel_size=kernel_size,
                              stride=stride,
                              padding=padding),
                  nn.InstanceNorm2d(num_features=out_channels,
                           affine=True))
        self.convLayer_gates = nn.Sequential(nn.Conv2d(in_channels=in_channels,
                                out_channels=out_channels,
                                kernel_size=kernel_size,
                                stride=stride,
                                padding=padding),
                    nn.InstanceNorm2d(num_features=out_channels,
                             affine=True))

    def forward(self, input):
        # GLU
        return self.convLayer(input) * torch.sigmoid(self.convLayer_gates(input))

class GLU(nn.Module):
    def __init__(self):
        super(GLU, self).__init__()
        # Custom Implementation because the Voice Conversion Cycle GAN
        # paper assumes GLU won't reduce the dimension of tensor by 2.

    def forward(self, input):
        return input * torch.sigmoid(input)

class PixelShuffle(nn.Module):
    def __init__(self, upscale_factor=2):
        super(PixelShuffle, self).__init__()
        # Custom Implementation because PyTorch PixelShuffle requires
        # 4D input. Whereas, in this case we have have 3D array
        # (∗,C×r^2,H,W) -> (∗,C,H×r,W×r)
        # upscale_factor: int
        self.upscale_factor = upscale_factor

    def forward(self, input):
        n = input.shape[0]
        c_out = input.shape[1] // self.upscale_factor
        w_new = input.shape[2] * self.upscale_factor
        return input.view(n, c_out, w_new)

class ResidualLayer(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        super(ResidualLayer, self).__init__()

        self.convLayer = nn.Sequential(nn.Conv2d(in_channels=in_channels,
                              out_channels=out_channels,
                              kernel_size=kernel_size,
                              stride=stride,
                              padding=padding),
                  nn.InstanceNorm2d(num_features=out_channels,
                           affine=True))
        self.convLayer_gates = nn.Sequential(nn.Conv2d(in_channels=in_channels,
                                out_channels=out_channels,
                                kernel_size=kernel_size,
                                stride=stride,
                                padding=padding),
                    nn.InstanceNorm2d(num_features=out_channels,
                             affine=True))

                          
        self.conv_out_layer = nn.Sequential(nn.Conv2d(in_channels=out_channels,
                                out_channels=in_channels,
                                kernel_size=kernel_size,
                                stride=stride,
                                padding=padding),
                    nn.InstanceNorm2d(num_features=in_channels,
                             affine=True))
        # IN : same shape as input
        # affine=True : this module has learnable affine parameters, initialized the same way as done for batch normalization

    def forward(self, input):
        h1_norm = self.convLayer(input)
        h1_gates_norm = self.convLayer_gates(input)

        # GLU
        h1_glu = h1_norm * torch.sigmoid(h1_gates_norm)

        h2_norm = self.conv_out_layer(h1_glu)

        # SUM
        return input + h2_norm

class upSample2(nn.Module):
  def __init__(self):
    super(upSample2, self).__init__()
    self.upconv = nn.Conv2d(in_channels=256,
          out_channels=512,
          kernel_size=(5,5),
          stride=(1,1),
          padding=(2,2))
    self.pixelshuffle = nn.PixelShuffle(2)
    self.INdown = nn.InstanceNorm2d(128, affine=False) # u2.size(1)

    self.mlp_shared1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU()) # in channel = A_rs.size(1)
    self.mlp_shared2 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU())
    self.mlp_shared3 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU())
    self.mlp_gamma = nn.Conv2d(in_channels=128, out_channels=128,  kernel_size=(5,5) , stride=(1,1), padding=(2,2)) # out_channels=INf.size(1)
    self.mlp_beta = nn.Conv2d(in_channels=128, out_channels=128,  kernel_size=(5,5) , stride=(1,1), padding=(2,2)) # out_channels=INf.size(1)

    self.upSample_step4 = GLU()
    


  def forward(self, input):
    x, segmap = input
    
    u1 = self.upconv(x)

    u2 = self.pixelshuffle(u1)


    INf = self.INdown(u2)


    A_rs = F.interpolate(segmap, size=INf.size()[2:], mode='nearest')

    A_h1 = self.mlp_shared1(A_rs)

    A_h2 = self.mlp_shared2(A_h1)
    A_h3 = self.mlp_shared3(A_h2)

    gamma = self.mlp_gamma(A_h3)
    beta = self.mlp_beta(A_h3)


    out = INf * gamma + beta # (1 + 

    output = self.upSample_step4(out)
    return output

class upSample(nn.Module):
  def __init__(self):
    super(upSample, self).__init__()
    self.upconv = nn.Conv2d(in_channels=512,
          out_channels=1024,
          kernel_size=(5,5),
          stride=(1,1),
          padding=(2,2))
    self.pixelshuffle = nn.PixelShuffle(2)
    self.INdown = nn.InstanceNorm2d(256, affine=False) # u2.size(1)
    self.mlp_shared1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU()) # in channel = A_rs.size(1)
    self.mlp_shared2 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU())
    self.mlp_shared3 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(5,5) , stride=(1,1), padding=(2,2)),
            nn.ReLU())
    self.mlp_gamma = nn.Conv2d(in_channels=128, out_channels=256,  kernel_size=(5,5) , stride=(1,1), padding=(2,2)) # out_channels=INf.size(1)
    self.mlp_beta = nn.Conv2d(in_channels=128, out_channels=256,  kernel_size=(5,5) , stride=(1,1), padding=(2,2)) # out_channels=INf.size(1)

    self.upSample_step4 = GLU()
    


  def forward(self, input):
    x, segmap = input
    
    u1 = self.upconv(x)
    u2 = self.pixelshuffle(u1)

    INf = self.INdown(u2)

    A_rs = F.interpolate(segmap, size=INf.size()[2:], mode='nearest')

    A_h1 = self.mlp_shared1(A_rs)

    A_h2 = self.mlp_shared2(A_h1)
    A_h3 = self.mlp_shared3(A_h2)

    gamma = self.mlp_gamma(A_h3)
    beta = self.mlp_beta(A_h3)


    out = INf * gamma + beta # (1 + 

    # 4d: [batch_size=1/70, channels=80, height=features=1, width=T=64]
    #out2d = out.view(out.size(0), 256, -1, out.size(3))

    output = self.upSample_step4(out)
    return output



