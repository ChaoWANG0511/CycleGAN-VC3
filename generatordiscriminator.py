# -*- coding: utf-8 -*-
"""generatordiscriminator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qxuW86Bmt6Fsxn3vb2mYf9pEhX-cX23L
"""

import numpy as np
import os
import argparse
import time
import librosa
import pickle
from tqdm import tqdm
import torch
import re
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.utils.spectral_norm as spectral_norm
import IPython.display as display
import gc
from torch.utils.data.dataset import Dataset


from google.colab import drive
drive.mount("/content/drive")

path="/content/drive/MyDrive/My_CycleGAN"
os.chdir(path)

from smallmodulles import downSample_Generator,GLU,PixelShuffle,ResidualLayer,upSample2,upSample

class Generator(nn.Module):
  def __init__(self):
    super(Generator, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1,  
          out_channels=128,
          kernel_size=(5, 15),
          stride=(1, 1),
          padding=(2, 7))
    self.glu = GLU()
    self.d1 = downSample_Generator(128, 256, (5,5), (2,2), 2) 
    self.d2 = downSample_Generator(256, 512, (5,5), (2,2), 2)
    self.conv2dto1d = nn.Sequential(nn.Conv2d(in_channels=10240, # F.size(1)
                    out_channels=256,
                    kernel_size=(1,1),
                    stride=(1,1),
                    padding=0),
          nn.InstanceNorm2d(num_features=256,affine=True))
    
    # 6 res blocks
    self.res1 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))
    self.res2 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))
    self.res3 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))
    self.res4 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))
    self.res5 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))
    self.res6 = ResidualLayer(in_channels=256, out_channels=512, kernel_size=(1,3), stride=(1,1), padding=(0,1))

    self.conv1dto2dLayer_step1 = nn.Conv2d(in_channels=256,
                  out_channels=10240,   # F.size(1)
                  kernel_size=(1,1),
                  stride=(1,1),
                  padding=0)
    self.INdown = nn.InstanceNorm2d(10240, affine=False) # I.size(1)

    self.mlp_shared1 = nn.Sequential(
            nn.Conv2d(in_channels=80, out_channels=128, kernel_size=(1,5) , stride=(1,1), padding=(0,2)),  # in_channels=320!!!!!!
            nn.ReLU())
    self.mlp_shared2 = nn.Sequential(
                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1,5) , stride=(1,1), padding=(0,2)),
                nn.ReLU())
    self.mlp_shared3 = nn.Sequential(
                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1,5) , stride=(1,1), padding=(0,2)),
                nn.ReLU())
    
    self.mlp_gamma = nn.Conv2d(in_channels=128, out_channels=10240, kernel_size=(1,5) , stride=(1,1), padding=(0,2)) # out_channels=INf.size(1)
    self.mlp_beta = nn.Conv2d(in_channels=128, out_channels=10240, kernel_size=(1,5) , stride=(1,1), padding=(0,2)) # out_channels=INf.size(1)

    self.upsam1 = upSample()
    self.upsam2 = upSample2()

    self.lastConvLayer = nn.Conv2d(in_channels=128,
              out_channels=1,
              kernel_size=(5, 15),
              stride=(1, 1),
              padding=(2, 7))

  def forward(self, A):
    B = self.conv1(A)
    C = self.glu.forward(B)
    D = self.d1.forward(C)
    E = self.d2.forward(D)
    F_v = E.view(E.size(0), -1, 1, E.size(-1))
    G = self.conv2dto1d(F_v)
    H1 = self.res1(G)
    H2 = self.res2(H1)
    H3 = self.res3(H2)
    H4 = self.res4(H3)
    H5 = self.res5(H4)
    H6 = self.res6(H5)
    I = self.conv1dto2dLayer_step1(H6)
    INf = self.INdown(I)
    #print('INf ', INf.shape) # torch.Size([1, 10240, 1, 67])

    # TFAN 1D
    A_ = A.squeeze(1).unsqueeze(2) # torch.Size([1, 80, 1, 267])

    #A_rs = A_.view(A_.size(0), -1, 1, INf.size(3)) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
    A_rs = F.interpolate(A_, size=INf.size()[2:], mode='nearest') 
    #print('A_rs ', A_rs.shape)


    A_h1 = self.mlp_shared1(A_rs)
    A_h2 = self.mlp_shared2(A_h1)
    A_h3 = self.mlp_shared3(A_h2)
    gamma = self.mlp_gamma(A_h3)
    beta = self.mlp_beta(A_h3)
    out = INf * gamma + beta

    out2d = out.view(out.size(0), 512, -1, out.size(3))

    out2d1 = self.upsam1.forward((out2d,A))
    out2d2 = self.upsam2.forward((out2d1,A))

    output = self.lastConvLayer(out2d2)

    return output

# 鉴别器  PatchGAN
# discriminator : kernel size in the second-last convolutional layer *2 in the frequency direction
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.convLayer1 = nn.Sequential(nn.Conv2d(in_channels=1,
                    out_channels=128,
                    kernel_size=(3, 3),
                    stride=(1, 1),
                    padding=(1, 1)),
                  GLU())

        # DownSample Layer
        self.d1 = downSample_Generator(in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(2, 2), padding=1)
        self.d2 = downSample_Generator(in_channels=256, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=1)
        self.d3 = downSample_Generator(in_channels=512, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=1)
        self.d4 = downSample_Generator(in_channels=1024, out_channels=1024, kernel_size=(2, 5), stride=(1, 1), padding=(1, 1))

        # Conv Layer
        self.outputConvLayer = nn.Conv2d(in_channels=1024,
                    out_channels=1,
                    kernel_size=(1, 3),
                    stride=(1,1),
                    padding=(0,1))

    def forward(self, input):
        B = self.convLayer1(input)

        C = self.d1.forward(B)
        D = self.d2.forward(C)
        E = self.d3.forward(D)
        F = self.d4.forward(E)

        G = self.outputConvLayer(F)

        output = torch.sigmoid(G)
        
        return output



